{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning v1 Image Classification Development\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Design and implement a custom neural network from scratch\n",
    "- Learn fundamental deep learning concepts through hands-on implementation\n",
    "- Compare performance with shallow learning approaches\n",
    "- Establish baseline for deep learning model improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from torchinfo import summary\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "from typing import Dict, Any, List, Tuple  # Added missing typing imports\n",
    "\n",
    "# Add parent directory to path for model core imports\n",
    "sys.path.append('../..')\n",
    "from ml_models_core.src.base_classifier import BaseImageClassifier\n",
    "from ml_models_core.src.model_registry import ModelRegistry, ModelMetadata\n",
    "from ml_models_core.src.utils import ModelUtils\n",
    "from ml_models_core.src.data_loaders import get_unified_classification_data\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedDataset(Dataset):\n",
    "    \"\"\"Memory-efficient dataset wrapper for unified classification data.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, class_names, transform=None):\n",
    "        self.image_paths = image_paths  # Store paths instead of loaded images\n",
    "        self.labels = labels\n",
    "        self.class_names = class_names\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image on-demand\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        try:\n",
    "            # Load image from disk\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {image_path}: {e}\")\n",
    "            # Create blank image if loading fails\n",
    "            image = Image.new('RGB', (224, 224), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Memory-efficient approach: Get image paths directly from the data manager\n",
    "print(\"Getting dataset paths directly from data manager...\")\n",
    "\n",
    "from ml_models_core.src.data_manager import get_dataset_manager\n",
    "manager = get_dataset_manager()\n",
    "\n",
    "# Get the unified dataset path\n",
    "try:\n",
    "    dataset_path = manager.get_dataset_path('combined_unified_classification')\n",
    "    if not dataset_path:\n",
    "        print(\"Creating unified classification dataset...\")\n",
    "        available_datasets = ['oxford_pets', 'kaggle_vegetables', 'street_foods', 'musical_instruments']\n",
    "        dataset_path = manager.create_combined_dataset(\n",
    "            dataset_names=available_datasets,\n",
    "            output_name=\"unified_classification\",\n",
    "            class_mapping=None  # Keep original class names\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(f\"Error accessing unified dataset: {e}\")\n",
    "    # Fallback to main dataset\n",
    "    dataset_path = manager.download_dataset('oxford_pets')\n",
    "\n",
    "print(f\"Using dataset at: {dataset_path}\")\n",
    "\n",
    "# Scan the dataset directory for image paths and labels\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dataset_path = Path(dataset_path)\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "class_names = []\n",
    "class_to_idx = {}\n",
    "\n",
    "# Collect all class directories\n",
    "class_dirs = [d for d in dataset_path.iterdir() \n",
    "             if d.is_dir() and not d.name.startswith('.')]\n",
    "\n",
    "if not class_dirs:\n",
    "    raise ValueError(f\"No class directories found in {dataset_path}\")\n",
    "\n",
    "class_names = sorted([d.name for d in class_dirs])\n",
    "class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "print(f\"Found {len(class_names)} classes: {class_names}\")\n",
    "\n",
    "# Collect all images efficiently - just paths, not loading images\n",
    "valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}\n",
    "\n",
    "print(\"Scanning for image paths...\")\n",
    "for class_dir in class_dirs:\n",
    "    class_name = class_dir.name\n",
    "    class_idx = class_to_idx[class_name]\n",
    "    \n",
    "    image_files = [f for f in class_dir.iterdir() \n",
    "                   if f.suffix.lower() in valid_extensions]\n",
    "    \n",
    "    print(f\"  {class_name}: {len(image_files)} images\")\n",
    "    \n",
    "    for img_path in image_files:\n",
    "        all_image_paths.append(str(img_path))\n",
    "        all_labels.append(class_idx)\n",
    "\n",
    "print(f\"\\nCollected {len(all_image_paths)} image paths\")\n",
    "print(f\"Memory usage: Only storing paths ({len(all_image_paths) * 100} bytes) instead of images ({len(all_image_paths) * 224 * 224 * 3 * 4 / 1e9:.1f} GB)\")\n",
    "\n",
    "# Convert labels to numpy array for consistency\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(f\"‚úÖ Memory-efficient data loading completed\")\n",
    "print(f\"Sample path: {all_image_paths[0]}\")\n",
    "print(f\"Classes: {len(class_names)} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms with 128x128 image size for optimal balance\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Sweet spot between detail and model capacity\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # Sweet spot between detail and model capacity\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create memory-efficient dataset with image paths only\n",
    "full_dataset = UnifiedDataset(all_image_paths, all_labels, class_names, transform=transform_train)\n",
    "\n",
    "# Split dataset indices (not actual data)\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "val_size = int(0.15 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "\n",
    "print(f\"Dataset splits:\")\n",
    "print(f\"  Total images: {len(full_dataset)}\")\n",
    "print(f\"  Training: {train_size}\")\n",
    "print(f\"  Validation: {val_size}\")\n",
    "print(f\"  Test: {test_size}\")\n",
    "\n",
    "# Create index splits\n",
    "indices = list(range(len(full_dataset)))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "# Create separate dataset instances with appropriate transforms\n",
    "train_dataset = UnifiedDataset(\n",
    "    [all_image_paths[i] for i in train_indices],\n",
    "    [all_labels[i] for i in train_indices],\n",
    "    class_names,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "val_dataset = UnifiedDataset(\n",
    "    [all_image_paths[i] for i in val_indices],\n",
    "    [all_labels[i] for i in val_indices],\n",
    "    class_names,\n",
    "    transform=transform_val\n",
    ")\n",
    "\n",
    "test_dataset = UnifiedDataset(\n",
    "    [all_image_paths[i] for i in test_indices],\n",
    "    [all_labels[i] for i in test_indices],\n",
    "    class_names,\n",
    "    transform=transform_val\n",
    ")\n",
    "\n",
    "# Create data loaders - can use larger batch size with 128x128\n",
    "batch_size = 8  # Increased back to 8 since 128x128 uses less memory than 256x256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"\\nDataLoaders created with batch_size={batch_size} for 128x128 images\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "\n",
    "# Test loading a single batch to verify everything works\n",
    "print(f\"\\nTesting data loading with 128x128 images...\")\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"‚úÖ Successfully loaded batch: {sample_batch[0].shape}, {sample_batch[1].shape}\")\n",
    "    print(f\"‚úÖ Memory-efficient loading working correctly with 128x128 images\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in data loading: {e}\")\n",
    "    \n",
    "# Clear any unnecessary variables to free memory\n",
    "import gc\n",
    "gc.collect()\n",
    "print(f\"‚úÖ Memory cleanup completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images\n",
    "def visualize_batch(data_loader, class_names, title=\"Sample Images\"):\n",
    "    \"\"\"Visualize a batch of images.\"\"\"\n",
    "    data_iter = iter(data_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    # Denormalize images for visualization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    images_denorm = images * std + mean\n",
    "    images_denorm = torch.clamp(images_denorm, 0, 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(8, len(images))):\n",
    "        img = images_denorm[i].permute(1, 2, 0)\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'{class_names[labels[i]]}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_batch(train_loader, class_names, \"Training Samples from Unified Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Architecture Design\n",
    "\n",
    "Now let's design our custom CNN architecture. We'll create a modular design with configurable depth and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLearningV1(nn.Module):\n",
    "    \"\"\"Custom CNN architecture for image classification with 128x128 input.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=70, input_channels=3, dropout_rate=0.5):\n",
    "        super(DeepLearningV1, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.input_channels = input_channels\n",
    "        \n",
    "        # Feature extraction layers - optimized for 128x128 input\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=6, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=6, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=6, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=6, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        # Pooling and regularization\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Classification head\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize model weights.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        # Input: 128x128x3\n",
    "        \n",
    "        # Block 1: 128x128 -> 64x64\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        \n",
    "        # Block 2: 64x64 -> 32x32  \n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        \n",
    "        # Block 3: 32x32 -> 16x16\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Block 4: 16x16 -> 8x8\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "        \n",
    "        # Block 5: 8x8 -> 4x4  \n",
    "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
    "        \n",
    "        # Global average pooling: 4x4 -> 1x1\n",
    "        x = self.adaptive_pool(x)\n",
    "        \n",
    "        # Flatten and classify\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_feature_maps(self, x, layer_names=None):\n",
    "        \"\"\"Extract feature maps from intermediate layers.\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Block 1\n",
    "        x1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        features['block1'] = x1\n",
    "        \n",
    "        # Block 2\n",
    "        x2 = self.pool(F.relu(self.bn2(self.conv2(x1))))\n",
    "        features['block2'] = x2\n",
    "        \n",
    "        # Block 3\n",
    "        x3 = self.pool(F.relu(self.bn3(self.conv3(x2))))\n",
    "        features['block3'] = x3\n",
    "        \n",
    "        # Block 4\n",
    "        x4 = self.pool(F.relu(self.bn4(self.conv4(x3))))\n",
    "        features['block4'] = x4\n",
    "        \n",
    "        # Block 5\n",
    "        x5 = self.pool(F.relu(self.bn5(self.conv5(x4))))\n",
    "        features['block5'] = x5\n",
    "        \n",
    "        return features if layer_names is None else {k: v for k, v in features.items() if k in layer_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model instance with correct number of classes for 128x128 input\n",
    "num_classes = len(class_names)\n",
    "model = DeepLearningV1(num_classes=num_classes).to(device)\n",
    "\n",
    "print(f\"Model created for {num_classes} classes with 128x128 input\")\n",
    "print(f\"Classes: {class_names}\")\n",
    "\n",
    "# Print model summary with correct input size\n",
    "print(\"\\nModel Architecture Summary:\")\n",
    "print(summary(model, input_size=(batch_size, 3, 128, 128), device=str(device)))\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size: {total_params * 4 / 1024 / 1024:.1f} MB (32-bit)\")\n",
    "\n",
    "# Test forward pass with sample data\n",
    "print(f\"\\nTesting forward pass...\")\n",
    "try:\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    with torch.no_grad():\n",
    "        sample_input = sample_batch[0].to(device)\n",
    "        sample_output = model(sample_input)\n",
    "        print(f\"‚úÖ Forward pass successful: {sample_input.shape} -> {sample_output.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Forward pass failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup and Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingManager:\n",
    "    \"\"\"Manages the training process for deep learning models with early stopping.\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device, class_names, patience=5, min_delta=0.001):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.class_names = class_names\n",
    "        \n",
    "        # Early stopping parameters\n",
    "        self.patience = patience  # Number of epochs to wait for improvement\n",
    "        self.min_delta = min_delta  # Minimum change to qualify as improvement\n",
    "        self.wait = 0  # Counter for patience\n",
    "        self.stopped_epoch = 0  # Track when early stopping occurred\n",
    "        \n",
    "        # Training history\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.val_accuracies = []\n",
    "        \n",
    "        # Best model tracking\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_accuracy = 0.0\n",
    "        self.best_model_state = None\n",
    "        \n",
    "    def train_epoch(self, train_loader, criterion, optimizer):\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            if batch_idx % 50 == 0:  # Reduce print frequency for many classes\n",
    "                print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100. * correct / total\n",
    "        \n",
    "        self.train_losses.append(epoch_loss)\n",
    "        self.train_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "        return epoch_loss, epoch_accuracy\n",
    "    \n",
    "    def validate_epoch(self, val_loader, criterion):\n",
    "        \"\"\"Validate for one epoch.\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                loss = criterion(output, target)\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(val_loader)\n",
    "        epoch_accuracy = 100. * correct / total\n",
    "        \n",
    "        self.val_losses.append(epoch_loss)\n",
    "        self.val_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "        return epoch_loss, epoch_accuracy\n",
    "    \n",
    "    def check_early_stopping(self, val_loss, epoch):\n",
    "        \"\"\"Check if training should stop early based on validation loss.\"\"\"\n",
    "        # Check if validation loss improved\n",
    "        if val_loss < self.best_val_loss - self.min_delta:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.best_model_state = self.model.state_dict().copy()\n",
    "            self.wait = 0\n",
    "            print(f\"üíö Validation loss improved to {val_loss:.4f} - saving best model\")\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            print(f\"‚ö†Ô∏è  Validation loss did not improve ({self.wait}/{self.patience})\")\n",
    "            \n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                print(f\"üõë Early stopping triggered at epoch {epoch + 1}\")\n",
    "                print(f\"   Best validation loss: {self.best_val_loss:.4f}\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def train(self, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n",
    "        \"\"\"Full training loop with early stopping.\"\"\"\n",
    "        print(f\"Starting training for up to {num_epochs} epochs...\")\n",
    "        print(f\"Training on {len(self.class_names)} classes\")\n",
    "        print(f\"Early stopping: patience={self.patience}, min_delta={self.min_delta}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            print(\"-\" * 20)\n",
    "            \n",
    "            # Training\n",
    "            train_loss, train_acc = self.train_epoch(train_loader, criterion, optimizer)\n",
    "            \n",
    "            # Validation\n",
    "            val_loss, val_acc = self.validate_epoch(val_loader, criterion)\n",
    "            \n",
    "            # Update learning rate\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "            \n",
    "            # Update best validation accuracy for tracking\n",
    "            if val_acc > self.best_val_accuracy:\n",
    "                self.best_val_accuracy = val_acc\n",
    "            \n",
    "            print(f\"Best Val Acc: {self.best_val_accuracy:.2f}%\")\n",
    "            \n",
    "            # Check for early stopping\n",
    "            if self.check_early_stopping(val_loss, epoch):\n",
    "                break\n",
    "            \n",
    "            # Plot progress every 5 epochs or if we're past epoch 10\n",
    "            if (epoch + 1) % 5 == 0 or epoch >= 10:\n",
    "                self.plot_training_progress()\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        \n",
    "        if self.stopped_epoch > 0:\n",
    "            print(f\"\\nüèÅ Training stopped early at epoch {self.stopped_epoch + 1}\")\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ Training completed all {num_epochs} epochs\")\n",
    "            \n",
    "        print(f\"Training time: {training_time:.2f} seconds\")\n",
    "        print(f\"Best validation loss: {self.best_val_loss:.4f}\")\n",
    "        print(f\"Best validation accuracy: {self.best_val_accuracy:.2f}%\")\n",
    "        \n",
    "        # Load best model\n",
    "        if self.best_model_state:\n",
    "            self.model.load_state_dict(self.best_model_state)\n",
    "            print(\"‚úÖ Loaded best model state\")\n",
    "        \n",
    "        return self.best_val_accuracy\n",
    "    \n",
    "    def plot_training_progress(self):\n",
    "        \"\"\"Plot training progress with overfitting indicators.\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(epochs, self.train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "        ax1.plot(epochs, self.val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "        \n",
    "        # Highlight potential overfitting\n",
    "        if len(self.train_losses) > 5:\n",
    "            # Check if validation loss is increasing while training loss decreases\n",
    "            recent_train = self.train_losses[-3:]\n",
    "            recent_val = self.val_losses[-3:]\n",
    "            \n",
    "            if len(recent_train) >= 3 and len(recent_val) >= 3:\n",
    "                train_trend = recent_train[-1] - recent_train[0]\n",
    "                val_trend = recent_val[-1] - recent_val[0]\n",
    "                \n",
    "                if train_trend < 0 and val_trend > 0:  # Train decreasing, val increasing\n",
    "                    ax1.axvspan(len(epochs)-2, len(epochs), alpha=0.3, color='orange', \n",
    "                               label='Potential Overfitting')\n",
    "        \n",
    "        ax1.set_title('Training and Validation Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Mark early stopping point if it occurred\n",
    "        if self.stopped_epoch > 0:\n",
    "            ax1.axvline(x=self.stopped_epoch + 1, color='red', linestyle='--', \n",
    "                       label=f'Early Stop (Epoch {self.stopped_epoch + 1})')\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax2.plot(epochs, self.train_accuracies, 'b-', label='Training Accuracy', linewidth=2)\n",
    "        ax2.plot(epochs, self.val_accuracies, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "        ax2.set_title('Training and Validation Accuracy')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Mark early stopping point if it occurred\n",
    "        if self.stopped_epoch > 0:\n",
    "            ax2.axvline(x=self.stopped_epoch + 1, color='red', linestyle='--', \n",
    "                       label=f'Early Stop (Epoch {self.stopped_epoch + 1})')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print overfitting analysis\n",
    "        if len(self.train_losses) > 5:\n",
    "            print(\"\\nüìä Overfitting Analysis:\")\n",
    "            print(f\"   Current train loss: {self.train_losses[-1]:.4f}\")\n",
    "            print(f\"   Current val loss: {self.val_losses[-1]:.4f}\")\n",
    "            print(f\"   Loss gap: {self.val_losses[-1] - self.train_losses[-1]:.4f}\")\n",
    "            \n",
    "            if self.val_losses[-1] > self.train_losses[-1] + 0.1:\n",
    "                print(\"   ‚ö†Ô∏è  Large gap suggests possible overfitting\")\n",
    "            else:\n",
    "                print(\"   ‚úÖ Loss gap looks healthy\")\n",
    "    \n",
    "    def evaluate_model(self, test_loader):\n",
    "        \"\"\"Evaluate model on test set.\"\"\"\n",
    "        self.model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                \n",
    "                total += target.size(0)\n",
    "                correct += (predicted == target).sum().item()\n",
    "                \n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "                all_targets.extend(target.cpu().numpy())\n",
    "        \n",
    "        test_accuracy = 100. * correct / total\n",
    "        \n",
    "        print(f\"\\nüéØ Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        \n",
    "        # Classification report (truncated for many classes)\n",
    "        print(\"\\nClassification Report (first 10 classes):\")\n",
    "        unique_classes = sorted(list(set(all_targets)))\n",
    "        display_classes = unique_classes[:10]\n",
    "        \n",
    "        if len(display_classes) < len(unique_classes):\n",
    "            print(f\"Note: Showing first 10 of {len(unique_classes)} classes\")\n",
    "        \n",
    "        print(classification_report(all_targets, all_predictions, \n",
    "                                  target_names=[self.class_names[i] for i in display_classes],\n",
    "                                  labels=display_classes))\n",
    "        \n",
    "        # Confusion matrix (for manageable number of classes)\n",
    "        if len(self.class_names) <= 15:\n",
    "            cm = confusion_matrix(all_targets, all_predictions)\n",
    "            \n",
    "            plt.figure(figsize=(12, 10))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                       xticklabels=self.class_names, yticklabels=self.class_names)\n",
    "            plt.title('Confusion Matrix')\n",
    "            plt.xlabel('Predicted')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Confusion matrix skipped (too many classes: {len(self.class_names)})\")\n",
    "        \n",
    "        return test_accuracy, all_predictions, all_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Create training manager with early stopping\n",
    "# patience=5 means stop if validation loss doesn't improve for 5 epochs\n",
    "# min_delta=0.001 means improvement must be at least 0.001 to count\n",
    "trainer = TrainingManager(model, device, class_names, patience=5, min_delta=0.001)\n",
    "\n",
    "# Train the model with early stopping\n",
    "num_epochs = 30  # Set higher limit since early stopping will prevent overfitting\n",
    "print(f\"üöÄ Starting training with early stopping monitoring...\")\n",
    "print(f\"   - Will stop if validation loss doesn't improve for {trainer.patience} epochs\")\n",
    "print(f\"   - Minimum improvement threshold: {trainer.min_delta}\")\n",
    "\n",
    "best_val_accuracy = trainer.train(\n",
    "    train_loader, val_loader, criterion, optimizer, scheduler, num_epochs\n",
    ")\n",
    "\n",
    "# Final training progress plot\n",
    "print(f\"\\nüìà Final Training Results:\")\n",
    "trainer.plot_training_progress()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_accuracy, predictions, targets = trainer.evaluate_model(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some test predictions\n",
    "def visualize_predictions(model, test_loader, class_names, device, num_samples=8):\n",
    "    \"\"\"Visualize model predictions on test samples.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of test data\n",
    "    data_iter = iter(test_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        images_gpu = images.to(device)\n",
    "        outputs = model(images_gpu)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "    \n",
    "    # Denormalize images for visualization\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    images_denorm = images * std + mean\n",
    "    images_denorm = torch.clamp(images_denorm, 0, 1)\n",
    "    \n",
    "    # Plot predictions\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        img = images_denorm[i].permute(1, 2, 0)\n",
    "        true_label = class_names[labels[i]]\n",
    "        pred_label = class_names[predicted[i]]\n",
    "        confidence = probabilities[i][predicted[i]].item()\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        \n",
    "        # Color based on correctness\n",
    "        color = 'green' if labels[i] == predicted[i] else 'red'\n",
    "        \n",
    "        axes[i].set_title(\n",
    "            f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2f}',\n",
    "            color=color\n",
    "        )\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Test Predictions (Green=Correct, Red=Incorrect)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(model, test_loader, full_dataset.class_names, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model performance by class\n",
    "def analyze_per_class_performance(targets, predictions, class_names):\n",
    "    \"\"\"Analyze performance for each class.\"\"\"\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    \n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        targets, predictions, average=None, labels=range(len(class_names))\n",
    "    )\n",
    "    \n",
    "    # Create DataFrame for easy visualization\n",
    "    import pandas as pd\n",
    "    \n",
    "    performance_df = pd.DataFrame({\n",
    "        'Class': class_names,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Support': support\n",
    "    })\n",
    "    \n",
    "    print(\"Per-Class Performance:\")\n",
    "    print(performance_df.round(3))\n",
    "    \n",
    "    # Plot metrics\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    metrics = ['Precision', 'Recall', 'F1-Score']\n",
    "    for i, metric in enumerate(metrics):\n",
    "        axes[i].bar(class_names, performance_df[metric])\n",
    "        axes[i].set_title(f'{metric} by Class')\n",
    "        axes[i].set_ylabel(metric)\n",
    "        axes[i].set_ylim(0, 1.1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for j, v in enumerate(performance_df[metric]):\n",
    "            axes[i].text(j, v + 0.02, f'{v:.3f}', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return performance_df\n",
    "\n",
    "performance_df = analyze_per_class_performance(targets, predictions, full_dataset.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature visualization - show what the model learned\n",
    "def visualize_conv_filters(model, layer_name='conv1'):\n",
    "    \"\"\"Visualize convolutional filters.\"\"\"\n",
    "    # Get the layer\n",
    "    layer = getattr(model, layer_name)\n",
    "    filters = layer.weight.data.cpu()\n",
    "    \n",
    "    # Normalize filters for visualization\n",
    "    filters = (filters - filters.min()) / (filters.max() - filters.min())\n",
    "    \n",
    "    # Plot first 16 filters\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(16, filters.shape[0])):\n",
    "        # Convert filter to displayable format\n",
    "        filter_img = filters[i].permute(1, 2, 0)\n",
    "        \n",
    "        if filter_img.shape[2] == 3:  # RGB filter\n",
    "            axes[i].imshow(filter_img)\n",
    "        else:  # Single channel\n",
    "            axes[i].imshow(filter_img[:, :, 0], cmap='gray')\n",
    "        \n",
    "        axes[i].set_title(f'Filter {i+1}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Learned Filters in {layer_name}', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize first layer filters\n",
    "visualize_conv_filters(model, 'conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Integration with Core Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLearningV1Classifier(BaseImageClassifier):\n",
    "    \"\"\"Deep Learning v1 classifier implementing the base interface.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name=\"deep-learning-v1\", version=\"1.0.0\"):\n",
    "        super().__init__(model_name, version)\n",
    "        self.model = None\n",
    "        self.class_names = None\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),  # Updated to 128x128 sweet spot\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def load_model(self, model_path: str) -> None:\n",
    "        \"\"\"Load the trained model.\"\"\"\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # Recreate model architecture\n",
    "        num_classes = len(checkpoint['class_names'])\n",
    "        self.model = DeepLearningV1(num_classes=num_classes)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.class_names = checkpoint['class_names']\n",
    "        self._is_loaded = True\n",
    "    \n",
    "    def preprocess(self, image: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Preprocess image for prediction.\"\"\"\n",
    "        # Convert numpy array to PIL Image\n",
    "        if image.dtype != np.uint8:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        \n",
    "        pil_image = Image.fromarray(image)\n",
    "        if pil_image.mode != 'RGB':\n",
    "            pil_image = pil_image.convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        tensor_image = self.transform(pil_image)\n",
    "        \n",
    "        return tensor_image\n",
    "    \n",
    "    def predict(self, image: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Make predictions on input image.\"\"\"\n",
    "        if not self.is_loaded:\n",
    "            raise ValueError(\"Model not loaded. Call load_model() first.\")\n",
    "        \n",
    "        # Preprocess image\n",
    "        tensor_image = self.preprocess(image)\n",
    "        tensor_image = tensor_image.unsqueeze(0).to(self.device)  # Add batch dimension\n",
    "        \n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tensor_image)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "        \n",
    "        # Convert to class name mapping\n",
    "        predictions = {}\n",
    "        for i, prob in enumerate(probabilities[0]):\n",
    "            predictions[self.class_names[i]] = float(prob.cpu())\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def get_metadata(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get model metadata.\"\"\"\n",
    "        return {\n",
    "            \"model_type\": \"deep_learning_v1\",\n",
    "            \"architecture\": \"Custom CNN with 5 conv layers\",\n",
    "            \"input_size\": \"128x128x3\",  # Updated input size\n",
    "            \"classes\": self.class_names,\n",
    "            \"parameters\": sum(p.numel() for p in self.model.parameters()) if self.model else 0,\n",
    "            \"device\": str(self.device),\n",
    "            \"version\": self.version\n",
    "        }\n",
    "    \n",
    "    def save_model(self, model_path: str, model, class_names, accuracy, training_history):\n",
    "        \"\"\"Save the trained model.\"\"\"\n",
    "        checkpoint = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'class_names': class_names,\n",
    "            'accuracy': accuracy,\n",
    "            'training_history': training_history,\n",
    "            'model_config': {\n",
    "                'num_classes': len(class_names),\n",
    "                'input_size': (128, 128),  # Updated input size\n",
    "                'architecture': 'DeepLearningV1'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        torch.save(checkpoint, model_path)\n",
    "        print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "deep_v1_classifier = DeepLearningV1Classifier()\n",
    "\n",
    "# Prepare training history\n",
    "training_history = {\n",
    "    'train_losses': trainer.train_losses,\n",
    "    'val_losses': trainer.val_losses,\n",
    "    'train_accuracies': trainer.train_accuracies,\n",
    "    'val_accuracies': trainer.val_accuracies\n",
    "}\n",
    "\n",
    "# Save model\n",
    "model_path = \"../models/deep_v1_classifier.pth\"\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "deep_v1_classifier.save_model(\n",
    "    model_path, model, class_names, test_accuracy, training_history\n",
    ")\n",
    "\n",
    "# Test the saved model\n",
    "test_classifier = DeepLearningV1Classifier()\n",
    "test_classifier.load_model(model_path)\n",
    "\n",
    "# Test prediction on a sample image\n",
    "sample_batch = next(iter(test_loader))\n",
    "sample_image = sample_batch[0][0]  # Get first image from batch\n",
    "sample_label = sample_batch[1][0]  # Get corresponding label\n",
    "\n",
    "# Convert tensor back to numpy for prediction\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "sample_image_denorm = sample_image * std + mean\n",
    "sample_image_denorm = torch.clamp(sample_image_denorm, 0, 1)\n",
    "sample_image_np = (sample_image_denorm.permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
    "\n",
    "predictions = test_classifier.predict(sample_image_np)\n",
    "print(f\"\\nSample prediction: {predictions}\")\n",
    "print(f\"Actual class: {class_names[sample_label]}\")\n",
    "\n",
    "# Register model in registry\n",
    "registry = ModelRegistry()\n",
    "metadata = ModelMetadata(\n",
    "    name=\"deep-learning-v1\",\n",
    "    version=\"1.0.0\",\n",
    "    model_type=\"deep_v1\",\n",
    "    accuracy=test_accuracy / 100.0,  # Convert percentage to decimal\n",
    "    training_date=\"2024-01-01\",\n",
    "    model_path=model_path,\n",
    "    config={\n",
    "        \"architecture\": \"Custom CNN\",\n",
    "        \"num_classes\": len(class_names),\n",
    "        \"input_size\": \"64x64x3\",\n",
    "        \"epochs_trained\": num_epochs,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"learning_rate\": 0.001\n",
    "    },\n",
    "    performance_metrics={\n",
    "        \"test_accuracy\": test_accuracy / 100.0,\n",
    "        \"best_val_accuracy\": best_val_accuracy / 100.0,\n",
    "        \"final_train_loss\": trainer.train_losses[-1],\n",
    "        \"final_val_loss\": trainer.val_losses[-1]\n",
    "    }\n",
    ")\n",
    "\n",
    "registry.register_model(metadata)\n",
    "print(f\"\\nModel registered with test accuracy: {test_accuracy:.2f}%\")\n",
    "print(f\"Total classes trained on: {len(class_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with shallow learning if available\n",
    "def compare_with_shallow_learning():\n",
    "    \"\"\"Compare performance with shallow learning baseline.\"\"\"\n",
    "    try:\n",
    "        # Try to load shallow learning results for comparison\n",
    "        shallow_registry = registry.get_model(\"shallow-classifier\")\n",
    "        \n",
    "        if shallow_registry:\n",
    "            shallow_accuracy = shallow_registry.accuracy * 100\n",
    "            deep_accuracy = test_accuracy\n",
    "            \n",
    "            print(f\"\\nModel Comparison:\")\n",
    "            print(f\"Shallow Learning Accuracy: {shallow_accuracy:.2f}%\")\n",
    "            print(f\"Deep Learning v1 Accuracy: {deep_accuracy:.2f}%\")\n",
    "            print(f\"Improvement: {deep_accuracy - shallow_accuracy:.2f}%\")\n",
    "            \n",
    "            # Plot comparison\n",
    "            models = ['Shallow Learning', 'Deep Learning v1']\n",
    "            accuracies = [shallow_accuracy, deep_accuracy]\n",
    "            \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            bars = plt.bar(models, accuracies, color=['skyblue', 'lightcoral'])\n",
    "            plt.title('Model Performance Comparison')\n",
    "            plt.ylabel('Accuracy (%)')\n",
    "            plt.ylim(0, 100)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, acc in zip(bars, accuracies):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                        f'{acc:.1f}%', ha='center', va='bottom')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Shallow learning model not found for comparison.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Could not compare with shallow learning: {e}\")\n",
    "\n",
    "compare_with_shallow_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Insights\n",
    "\n",
    "### Model Architecture:\n",
    "- **Custom CNN**: 5 convolutional layers with batch normalization (optimized for 128x128 input)\n",
    "- **Feature Progression**: 3 ‚Üí 32 ‚Üí 64 ‚Üí 128 ‚Üí 256 ‚Üí 512 channels\n",
    "- **Input Resolution**: 128x128x3 (sweet spot between detail and model capacity)\n",
    "- **Regularization**: Dropout, batch normalization, data augmentation\n",
    "- **Global Average Pooling**: Reduces overfitting compared to fully connected layers\n",
    "\n",
    "### Training Strategy:\n",
    "- **Optimal Resolution**: 128x128 balances detail capture with computational efficiency\n",
    "- **Memory-Efficient Loading**: On-demand image loading to handle large datasets\n",
    "- **Data Augmentation**: Random flips, rotations, color jittering\n",
    "- **Optimization**: Adam optimizer with learning rate scheduling\n",
    "- **Early Stopping**: Based on validation accuracy\n",
    "- **Monitoring**: Real-time loss and accuracy tracking\n",
    "\n",
    "### Resolution Analysis Results:\n",
    "1. **64x64**: Best performance initially due to simpler learning task\n",
    "2. **256x256**: Too much detail for current model capacity, may overfit\n",
    "3. **128x128**: Expected sweet spot - enough detail without overwhelming the model\n",
    "\n",
    "### Key Benefits of 128x128:\n",
    "- **Balanced Complexity**: 4x more detail than 64x64, but manageable for training\n",
    "- **Better Memory Usage**: More efficient than 256x256, allows larger batch sizes\n",
    "- **Optimal Learning**: Sufficient detail for discrimination without overfitting\n",
    "- **Faster Training**: Quicker than 256x256 while maintaining good accuracy\n",
    "\n",
    "### Memory Considerations:\n",
    "- **Image Size**: 128x128 = 4x more pixels than 64x64\n",
    "- **Batch Size**: Can maintain batch_size=8 with good GPU memory usage\n",
    "- **Model Complexity**: 5 layers handle 128x128 efficiently\n",
    "- **Training Speed**: Good balance between speed and accuracy\n",
    "\n",
    "### Expected Performance:\n",
    "- **Better than 64x64**: More detail for fine-grained classification\n",
    "- **Better than 256x256**: Avoids overfitting and excessive computational load\n",
    "- **Optimal Training**: Model capacity matches input complexity\n",
    "- **Good Convergence**: Expected stable training with good final accuracy\n",
    "\n",
    "### Production Readiness:\n",
    "- Model integrated with core framework\n",
    "- Saved in portable format for deployment\n",
    "- Compatible with ensemble classifier\n",
    "- Ready for API integration with 128x128 input standardization\n",
    "\n",
    "### Next Steps:\n",
    "1. **Performance Validation**: Confirm 128x128 outperforms both 64x64 and 256x256\n",
    "2. **Hyperparameter Tuning**: Optimize learning rate and batch size for 128x128\n",
    "3. **Architecture Refinement**: Consider adding skip connections if needed\n",
    "4. **Ensemble Integration**: Combine with other models for maximum accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
